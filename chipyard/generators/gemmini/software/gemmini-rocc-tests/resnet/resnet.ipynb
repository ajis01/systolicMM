{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_content = '''\n",
    "# #include <stdio.h>\n",
    "# #include \"include/gemmini.h\"\n",
    "\n",
    "# #define LEN(arr) ((int) (sizeof (arr) / sizeof (arr[0])))\n",
    "\n",
    "# '''\n",
    "# batch_size=32\n",
    "# input_dim=3036\n",
    "# param_file_name=\"parameters8.h\"\n",
    "# test_file_name=\"test8.c\"\n",
    "# if(batch_size%SYS_DIM !=0):\n",
    "#     print('please use a batch size of SYS_DIM')\n",
    "#     exit(1)   \n",
    "# #layers = [input_dim,2500,2000,1500,1000,500,10]\n",
    "# layers=[input_dim,4554,3036]\n",
    "# mlp='// batch size: ' + str(batch_size) +'\\n'\n",
    "# mlp+='// before zeropad: '\n",
    "# for l in layers:\n",
    "#     mlp=mlp+str(l)+'x'\n",
    "    \n",
    "# parameters_content = parameters_content+mlp[:-1]+'\\n'\n",
    "# for i,l in enumerate(list(layers)):\n",
    "#     layers[i] = int((l+SYS_DIM-1)/SYS_DIM)*SYS_DIM\n",
    "    \n",
    "# mlp='// after zeropad: '\n",
    "# for l in layers:\n",
    "#     mlp=mlp+str(l)+'x'\n",
    "# parameters_content = parameters_content+mlp[:-1]+'\\n'\n",
    "\n",
    "# input_mat = 'static elem_t input_mat[{0}][{1}] row_align(1)= '.format(batch_size,layers[0]) + '{0};\\n'\n",
    "# parameters_content = parameters_content+input_mat;\n",
    "\n",
    "# matmuls = []\n",
    "# for i,(l1,l2) in enumerate(zip(layers[:-1],layers[1:])):\n",
    "#     matrix = 'static elem_t weights'+str(i)+'['+str(l1)+']'+'['+str(l2)+'] row_align(1)= {0};\\n'\n",
    "#     parameters_content = parameters_content+matrix\n",
    "#     inter_results = 'static elem_t inter_results'+str(i)+'['+str(batch_size)+']'+'['+str(l2)+'] row_align(1)= {0};\\n'\n",
    "#     parameters_content = parameters_content+inter_results\n",
    "#     if i==0:\n",
    "#         matmuls.append(('input_mat',batch_size,'weights'+str(i),l1,'inter_results'+str(i),l2))\n",
    "#     else:\n",
    "#         matmuls.append(('inter_results'+str(i-1),batch_size,'weights'+str(i),l1,'inter_results'+str(i),l2))\n",
    "\n",
    "# f = open(param_file_name, \"w\")\n",
    "# f.write(parameters_content)\n",
    "# f.close()\n",
    "from math import sqrt\n",
    "test_file_name='resnet50-16.c'\n",
    "SYS_DIM=16\n",
    "test_content= '''\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "#include <stdbool.h>\n",
    "#include <sys/mman.h>\n",
    "#include \"include/gemmini.h\"\n",
    "\n",
    "#define verbose(layer_num,old_C,filter,C) printf(\"layer %d: operand %d %d filter %d %d result %d %d\\\\n\", layer_num, LEN(old_C),LEN(old_C[0]),LEN(filter),LEN(filter[0]),LEN(C),LEN(C[0]));\n",
    "#define LEN(arr) ((int) (sizeof (arr) / sizeof (arr[0])))\n",
    "#define N 224\n",
    "\n",
    "\n",
    "static void tensor_reshape(int channels, elem_t in_tensor[][channels],int dim1,int dim2,int kdim, int stride, elem_t out_tensor[][channels]){\n",
    "    int w1,w2,channel,i,j;\n",
    "    int k = 0;\n",
    "    int row = 0;\n",
    "    for (w1=0;w1<dim1;w1+=stride){\n",
    "        for(w2=0;w2<dim2;w2+=stride){\n",
    "            k=0;\n",
    "            for(channel = 0; channel<channels; channel++){\n",
    "                for(i=-kdim/2;i<=kdim/2;i++){\n",
    "                    for(j=-kdim/2;j<=kdim/2;j++){\n",
    "                        if(i+w1<0 || i+w1>=dim1||j+w2<0 ||j+w2>=dim2)\n",
    "                            out_tensor[row][k]=0;\n",
    "                        else\n",
    "                            out_tensor[row][k]=in_tensor[dim2*(i+w1)+j+w2][channel];\n",
    "                        k++;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            row++; \n",
    "        }\n",
    "    }\n",
    "}    \n",
    "static void avg_pool7(int len, elem_t in[][len],elem_t out[][len]){\n",
    "    int i, j;\n",
    "    for(i=0;i<len;i++){\n",
    "        for(j=0;j<7*7;j++){\n",
    "            out[0][i] += in[j][i];\n",
    "        }\n",
    "        out[0][i]=out[0][i]/49;\n",
    "    }\n",
    "}\n",
    "\n",
    "static void rocket_fix_strided_dimension(int img_dim, int len2, elem_t in[][len2], int len3, elem_t out[][len3]){\n",
    "        \n",
    "    for(int i =0;i<img_dim;i+=2){\n",
    "        for(int k = 0; k<img_dim;k+=2)\n",
    "            for(int j=0;j<len2; j+=1){\n",
    "                out[(i/2)*img_dim+k/2][j]=in[i*img_dim+k][j];\n",
    "\n",
    "            }\n",
    "    }\n",
    "}\n",
    "\n",
    "static void rocket_zeropad(int dim1,int dim2, elem_t in[][dim2], int dim3, elem_t out[][dim3]){\n",
    "    for(int i = 0; i<dim1;i++){\n",
    "        for(int j =0; j<dim2;j++){\n",
    "            out[i][j] = in[i][j];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "static void tiled_matmul_compare(size_t DIM_I, size_t DIM_J, size_t DIM_K,\n",
    "        // elem_t A[DIM_I][DIM_K], elem_t B[DIM_K][DIM_J], acc_t D[DIM_I][DIM_J],\n",
    "        elem_t A[DIM_I][DIM_K], elem_t B[DIM_K][DIM_J], void * D,\n",
    "        elem_t C[DIM_I][DIM_J],\n",
    "        int act, int shift, int relu6_shift, int full_bias_width,\n",
    "        enum tiled_matmul_type_t tiled_matmul_type,\n",
    "        bool compare, char * layer_name)\n",
    "{\n",
    "    if (compare)\n",
    "        printf(\"%s: gemmini\\\\n\", layer_name);\n",
    "    tiled_matmul_option(DIM_I, DIM_J, DIM_K,\n",
    "        A, B, D, C, act, shift, relu6_shift, full_bias_width,\n",
    "        tiled_matmul_type);\n",
    "\n",
    "    if (compare) {\n",
    "        printf(\"%s: CPU\\\\n\", layer_name);\n",
    "        elem_t gold[DIM_I][DIM_J];\n",
    "        tiled_matmul_option(DIM_I, DIM_J, DIM_K,\n",
    "            A, B, D, gold, act, shift, relu6_shift, full_bias_width,\n",
    "            CPU);\n",
    "\n",
    "        if (!MAT_IS_EQUAL(DIM_I, DIM_J, C, gold)) {\n",
    "            printf(\"Layer calculated incorrectly: %s\\\\n\", layer_name);\n",
    "            exit(1);\n",
    "        }\n",
    "    }\n",
    "}   \n",
    "\n",
    "int main (int argc, char * argv[]) {\n",
    "#ifndef BAREMETAL\n",
    "    if (mlockall(MCL_CURRENT | MCL_FUTURE) != 0) {\n",
    "      perror(\"mlockall failed\");\n",
    "      exit(1);\n",
    "    }\n",
    "#endif\n",
    "\n",
    "    matmul_flush(0);\n",
    "\n",
    "    enum tiled_matmul_type_t tiled_matmul_type;\n",
    "    if (argc < 2) {\n",
    "        // printf(\"usage: %s matmul_option\\\\n  matmul_option may be 'os', 'ws', or cpu'\\\\n\");\n",
    "        // exit(0);\n",
    "        tiled_matmul_type = OS;\n",
    "    } else if (strcmp(argv[1], \"cpu\") == 0) {\n",
    "        tiled_matmul_type = CPU;\n",
    "    } else if (strcmp(argv[1], \"os\") == 0) {\n",
    "        tiled_matmul_type = OS;\n",
    "    } else if (strcmp(argv[1], \"ws\") == 0) {\n",
    "        tiled_matmul_type = WS;\n",
    "    }\n",
    "\n",
    "    bool compare;\n",
    "    if (argc < 3) {\n",
    "        compare = false;\n",
    "    } else if (strcmp(argv[2], \"compare\") == 0) {\n",
    "        compare = true;\n",
    "    } else {\n",
    "        printf(\"Unknown command-line argument\\\\n\");\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "\n",
    "'''\n",
    "model = [(7,3,64,2),(3,64,64,2)]+[(1,64,64,1),(3,64,64,1),(1,64,256,1)]+[(1,64,64,1),(3,64,64,1),(1,64,256,1)]*2+[(1,256,128,1),(3,128,128,2),(1,128,512,1)]+[(1,256,128,1),(3,128,128,1),(1,128,512,1)]*3+[(1,512,256,1),(3,256,256,2),(1,256,1024,1)]+[(1,512,256,1),(3,256,256,1),(1,256,1024,1)]*5+[(1,1024,512,1),(3,512,512,2),(1,512,2048,1)]+[(1,1024,512,1),(3,512,512,1),(1,512,2048,1)]*2\n",
    "\n",
    "test_content += '    static elem_t img[N*N][3] = {0};\\n'\n",
    "test_content =  test_content + '    unsigned long cycles['+str(len(model)+2)+']={0};\\n'\n",
    "test_content =  test_content + '    unsigned long start,end;\\n'\n",
    "test_content =  test_content + '    start = read_cycles();\\n'\n",
    "\n",
    "def zeropadded_value(dim):\n",
    "    return int((dim+SYS_DIM-1)/SYS_DIM)*SYS_DIM\n",
    "\n",
    "def conv_to_matrix(filter_dim,img_dim,input_channels,output_channels,stride,test_content,layer,prev_tensor_name):\n",
    "    kernel_rows = zeropadded_value(filter_dim*filter_dim*input_channels)\n",
    "    kernel_cols = zeropadded_value(output_channels)\n",
    "    tensor_rows = zeropadded_value(int((img_dim+stride-1)/stride)*int((img_dim+stride-1)/stride))\n",
    "    tensor_cols = kernel_rows\n",
    "    test_content += '    static elem_t kernel'+str(layer)+'['+str(kernel_rows)+']'+'['+str(kernel_cols)+'] row_align(1)= {0};\\n'\n",
    "    test_content += '    static elem_t tensor'+str(layer)+'['+str(tensor_rows)+']'+'['+str(tensor_cols)+'] row_align(1)= {0};\\n' \n",
    "    test_content += '    static elem_t result'+str(layer)+'['+str(tensor_rows)+']'+'['+str(kernel_cols)+'] row_align(1)= {0};\\n' \n",
    "\n",
    "    if(filter_dim>1):\n",
    "        test_content += '    tensor_reshape('+str(input_channels)+',' + prev_tensor_name+','+str(img_dim)+', '+str(img_dim)+', '+ str(filter_dim)+', '+str(stride)+', tensor'+str(layer)+');\\n'\n",
    "    return test_content,tensor_rows,kernel_cols,kernel_rows\n",
    "        \n",
    "def matmul_layer(test_content,layer,tensor_rows,kernel_cols,kernel_rows,new_result_name,fix_dimensions = False):\n",
    "    \n",
    "    test_content +='\\n\\n    /* matmul number: {0} */\\n\\n'.format(str(layer))\n",
    "    test_content +='    tiled_matmul_compare({0}, {1}, {2},    // dimensions\\n'.format(tensor_rows,kernel_cols,kernel_rows)\n",
    "    if not fix_dimensions:\n",
    "        test_content +='    {0}, {1}, NULL, {2},      // addresses\\n'.format('tensor'+str(layer),'kernel'+str(layer),new_result_name)\n",
    "    else:\n",
    "        test_content +='    {0}, {1}, {2}, {3},      // addresses\\n'.format('tensor'+str(layer),'kernel'+str(layer),'inter_result'+str(layer),new_result_name)\n",
    "\n",
    "    test_content +='    RELU, 0, 0, 0,              // activation, shift, r6_shift, full_width_bias\\n'\n",
    "    test_content +='    tiled_matmul_type, compare, \"layer_'+str(layer)+'\");\\n'\n",
    "    test_content +='    // verbose({0},{1},{2},{3})\\n'.format(layer,'tensor'+str(layer),'kernel'+str(layer),new_result_name)\n",
    "    test_content +='    /* end of matmul number: {0} */\\n\\n'.format(str(layer))\n",
    "    test_content +='    end = read_cycles();\\n'\n",
    "    test_content +='    cycles['+str(layer)+'] = end-start;\\n'\n",
    "    test_content +='    start = end;\\n'\n",
    "    return test_content\n",
    "\n",
    "#(kernel_dim,input_channels,output_channels,stride)\n",
    "img_dim = 224\n",
    "prev_layers = []\n",
    "for m,(kernel_dim,input_channels,output_channels,stride) in enumerate(model):\n",
    "    prev_res_name='result'+str(m-1)\n",
    "    new_result_name = 'result'+str(m)\n",
    "    if m == 0:\n",
    "        prev_res_name = 'img'\n",
    "    test_content,tensor_rows,kernel_cols,kernel_rows = conv_to_matrix(kernel_dim,img_dim,input_channels,\n",
    "                                                                      output_channels,stride,test_content,\n",
    "                                                                      m,prev_res_name)\n",
    "    prev_layers.append((tensor_rows,kernel_cols,kernel_rows))\n",
    "    fix_dimensions = False\n",
    "    if m >=4:\n",
    "        if (m-4)%3 == 0:\n",
    "            \n",
    "            tr,kc,kr = prev_layers[m-2]\n",
    "            if tr != tensor_rows:\n",
    "                test_content += '    static elem_t inter_result'+str(m)+'['+str(tensor_rows)+']'+'['+str(kernel_cols)+'] row_align(1)= {0};\\n' \n",
    "                test_content += '    rocket_fix_strided_dimension('+str(int(sqrt(tr)))+','+str(kc)+',result' + str(m-2)+',' +str(kernel_cols)+',  inter_result'+str(m)+');\\n'\n",
    "            elif kc != kernel_cols and tr==tensor_rows:\n",
    "                test_content += '    static elem_t inter_result'+str(m)+'['+str(tensor_rows)+']'+'['+str(kernel_cols)+'] row_align(1)= {0};\\n' \n",
    "                test_content += '    rocket_zeropad('+str(tr)+','+str(kc)+',result' + str(m-2)+',' +str(kernel_cols)+',  inter_result'+str(m)+');\\n'\n",
    "            \n",
    "            fix_dimensions = True\n",
    "            \n",
    "    test_content = matmul_layer(test_content,m,tensor_rows,kernel_cols,kernel_rows,new_result_name,fix_dimensions)\n",
    "    img_dim=int(img_dim/stride)\n",
    "\n",
    "\n",
    "test_content +='\\n\\n    /* AVG Pool: {0} */\\n\\n'.format(str(len(model)))\n",
    "test_content += '    static elem_t tensor'+str(len(model)+1)+'['+str(SYS_DIM)+']'+'['+str(kernel_cols)+'] row_align(1)= {0};\\n' \n",
    "test_content +='    avg_pool7(2048,'+'result'+str(len(model)-1)+',tensor'+str(len(model)+1)+');\\n'\n",
    "test_content +='    end = read_cycles();\\n'\n",
    "test_content +='    cycles['+str(len(model))+'] = end-start;\\n'\n",
    "test_content +='    start = end;\\n'\n",
    "\n",
    "\n",
    "test_content += '\\n\\n    static elem_t kernel'+str(len(model)+1)+'['+str(2048)+']'+'['+str(zeropadded_value(1000))+'] row_align(1)= {0};\\n'\n",
    "test_content += '    static elem_t result'+str(len(model)+1)+'['+str(SYS_DIM)+']'+'['+str(zeropadded_value(1000))+'] row_align(1)= {0};\\n' \n",
    "\n",
    "test_content = matmul_layer(test_content,len(model)+1,SYS_DIM,zeropadded_value(1000),2048,'result'+str(len(model)+1))\n",
    "\n",
    "\n",
    "test_content +='''\n",
    "    unsigned long overall_cycles = 0;\n",
    "    for(int cyc = 0; cyc < '''+str(len(model)+2)+''' ; cyc++){\n",
    "        overall_cycles += cycles[cyc];\n",
    "    }\n",
    "    for(int cyc = 0; cyc < '''+str(len(model)+2)+''' ; cyc++){\n",
    "        printf(\"Cycles taken in layer %d: %lu, %lf\\\\n\", cyc,cycles[cyc],cycles[cyc]*1.0/(1.0*overall_cycles));\n",
    "    }\n",
    "    printf(\"Overall cycles taken: %lu\\\\n\",overall_cycles);\n",
    "\\n\n",
    "    return 0;\n",
    "}\\n\n",
    "''' \n",
    "\n",
    "f = open(test_file_name, \"w\")\n",
    "f.write(test_content)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
